# interpretability

I'm attempting to replicate and extend the paper [In-Context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#:~:text=Induction%20heads%20are%20named%20by,Induction%20heads%20crystallize%20that%20inference.
).

Part 1: Get familiar with the transformer implementation
- [x] Read + write notes for Attention is All You Need and The Annotated Transformer
- [x] Run the existing Annotated Transformer implementation in google collab
- [ ] Adapt it to run locally
  - [ ] Extract classes into their own files
  - [ ] Convert plots to matplotlib
